# üìö C√ÅC B∆Ø·ªöC TH·ª∞C HI·ªÜN ƒê·ªÇ TRAIN M√î H√åNH

## üéØ T·ªîNG QUAN WORKFLOW

```
Chu·∫©n b·ªã ‚Üí Ti·ªÅn x·ª≠ l√Ω ‚Üí X√¢y d·ª±ng ‚Üí Compile ‚Üí Train ‚Üí ƒê√°nh gi√° ‚Üí L∆∞u
```

---

## B∆Ø·ªöC 1: üìÅ CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG V√Ä DATASET

### **1.1. M√¥i tr∆∞·ªùng**

```python
# Ch·∫°y tr√™n Google Colab (c√≥ GPU mi·ªÖn ph√≠)
from google.colab import drive
drive.mount('/content/drive')
```

- Mount Google Drive ƒë·ªÉ truy c·∫≠p dataset
- S·ª≠ d·ª•ng GPU c·ªßa Colab ƒë·ªÉ train nhanh h∆°n

### **1.2. Import th∆∞ vi·ªán**

```python
import tensorflow as tf
import matplotlib.pyplot as plt
import json
```

- **TensorFlow**: Framework Deep Learning
- **Matplotlib**: V·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£
- **JSON**: L∆∞u l·ªãch s·ª≠ training

### **1.3. C·∫•u tr√∫c dataset**

```
Fruits_Vegetable_Recognition/
‚îú‚îÄ‚îÄ train/           # 3,600 ·∫£nh (100/class √ó 36 classes)
‚îú‚îÄ‚îÄ validation/      # 360 ·∫£nh (10/class √ó 36 classes)
‚îî‚îÄ‚îÄ test/           # 360 ·∫£nh (10/class √ó 36 classes)
```

---

## B∆Ø·ªöC 2: üîÑ TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (DATA PREPROCESSING)

### **2.1. Load Training Set**

```python
training_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Fruits_Vegetable_Recognition/train',
    labels="inferred",              # T·ª± ƒë·ªông g√°n nh√£n t·ª´ t√™n th∆∞ m·ª•c
    label_mode="categorical",       # One-hot encoding cho 36 classes
    color_mode="rgb",               # ·∫¢nh m√†u 3 channels
    batch_size=32,                  # 32 ·∫£nh/batch
    image_size=(64, 64),            # Resize v·ªÅ 64√ó64 pixels
    shuffle=True,                   # X√°o tr·ªôn d·ªØ li·ªáu
    interpolation="bilinear"        # Ph∆∞∆°ng ph√°p resize
)
```

### **2.2. Load Validation Set**

```python
validation_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Fruits_Vegetable_Recognition/validation',
    labels="inferred",
    label_mode="categorical",
    color_mode="rgb",
    batch_size=32,
    image_size=(64, 64),
    shuffle=True,
    interpolation="bilinear"
)
```

### **T·∫°i sao c·∫ßn preprocessing?**

- ‚úÖ **Resize uniform**: T·∫•t c·∫£ ·∫£nh ph·∫£i c√πng k√≠ch th∆∞·ªõc (64√ó64)
- ‚úÖ **Batch processing**: X·ª≠ l√Ω 32 ·∫£nh c√πng l√∫c ‚Üí hi·ªáu qu·∫£
- ‚úÖ **Shuffle**: Tr√°nh model h·ªçc theo th·ª© t·ª± ‚Üí tƒÉng generalization
- ‚úÖ **Categorical labels**: Chuy·ªÉn class th√†nh vector [0,0,1,0,...,0]

---

## B∆Ø·ªöC 3: üèóÔ∏è X√ÇY D·ª∞NG KI·∫æN TR√öC M√î H√åNH CNN

### **3.1. Kh·ªüi t·∫°o model Sequential**

```python
cnn = tf.keras.models.Sequential()
```

### **3.2. BLOCK 1: Feature Extraction (L·ªõp n√¥ng)**

```python
# Convolutional layers ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
cnn.add(tf.keras.layers.Conv2D(
    filters=32,              # 32 b·ªô l·ªçc
    kernel_size=3,           # Kernel 3√ó3
    padding='same',          # Gi·ªØ nguy√™n k√≠ch th∆∞·ªõc
    activation='relu',       # H√†m k√≠ch ho·∫°t ReLU
    input_shape=[64,64,3]    # Input: 64√ó64 RGB
))
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))

# Pooling ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))  # 64√ó64 ‚Üí 32√ó32

# Dropout ƒë·ªÉ ch·ªëng overfitting
cnn.add(tf.keras.layers.Dropout(0.25))  # T·∫Øt 25% neurons ng·∫´u nhi√™n
```

### **3.3. BLOCK 2: Deep Features (L·ªõp s√¢u)**

```python
# L·ªõp Conv2D s√¢u h∆°n v·ªõi nhi·ªÅu filters
cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))  # 32√ó32 ‚Üí 16√ó16
cnn.add(tf.keras.layers.Dropout(0.25))
```

### **3.4. BLOCK 3: Fully Connected Layers (Classification)**

```python
# Flatten: Chuy·ªÉn feature maps 2D ‚Üí vector 1D
cnn.add(tf.keras.layers.Flatten())

# Dense layers ƒë·ªÉ ph√¢n lo·∫°i
cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))
cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))
cnn.add(tf.keras.layers.Dropout(0.5))  # Dropout cao h∆°n cho FC layers

# Output layer
cnn.add(tf.keras.layers.Dense(units=36, activation='softmax'))  # 36 classes
```

### **Gi·∫£i th√≠ch ki·∫øn tr√∫c:**

- **Conv2D**: H·ªçc patterns (edges, textures, shapes)
- **MaxPooling**: Gi·∫£m k√≠ch th∆∞·ªõc, gi·ªØ l·∫°i info quan tr·ªçng
- **Dropout**: Regularization ƒë·ªÉ tr√°nh overfitting
- **Dense**: K·∫øt h·ª£p features ƒë·ªÉ ph√¢n lo·∫°i
- **Softmax**: Output probabilities t·ªïng = 1.0

---

## B∆Ø·ªöC 4: ‚öôÔ∏è COMPILE MODEL

```python
cnn.compile(
    optimizer='adam',                      # Adam optimizer (adaptive learning rate)
    loss='categorical_crossentropy',       # Loss function cho multi-class
    metrics=['accuracy']                   # Metric ƒë·ªÉ track
)
```

### **Xem t√≥m t·∫Øt model:**

```python
cnn.summary()
```

Output:

```
Total params: ~5 tri·ªáu parameters
Trainable params: ~5 tri·ªáu
Non-trainable params: 0
```

---

## B∆Ø·ªöC 5: üöÄ TRAINING MODEL

```python
training_history = cnn.fit(
    x=training_set,                    # Training data
    validation_data=validation_set,    # Validation data
    epochs=32                          # Train qua 32 epochs
)
```

### **Qu√° tr√¨nh training:**

```
Epoch 1/32: loss: 2.5 - accuracy: 0.30 - val_loss: 2.0 - val_accuracy: 0.45
Epoch 2/32: loss: 1.8 - accuracy: 0.50 - val_loss: 1.5 - val_accuracy: 0.60
...
Epoch 32/32: loss: 0.15 - accuracy: 0.95 - val_loss: 0.25 - val_accuracy: 0.92
```

- M·ªói epoch: Model xem qua to√†n b·ªô training set 1 l·∫ßn
- Sau m·ªói epoch: ƒê√°nh gi√° tr√™n validation set
- Th·ªùi gian: ~30-60 ph√∫t (t√πy GPU)

---

## B∆Ø·ªöC 6: üìä ƒê√ÅNH GI√Å M√î H√åNH

### **6.1. ƒê√°nh gi√° tr√™n Training Set**

```python
train_loss, train_acc = cnn.evaluate(training_set)
print('Training accuracy:', train_acc)  # ~95%
```

### **6.2. ƒê√°nh gi√° tr√™n Validation Set**

```python
val_loss, val_acc = cnn.evaluate(validation_set)
print('Validation accuracy:', val_acc)  # ~92-94%
```

### **6.3. ƒê√°nh gi√° tr√™n Test Set (Final)**

```python
test_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Fruits_Vegetable_Recognition/test',
    labels="inferred",
    label_mode="categorical",
    color_mode="rgb",
    batch_size=32,
    image_size=(64, 64),
    shuffle=True,
    interpolation="bilinear"
)
test_loss, test_acc = cnn.evaluate(test_set)
print('Test accuracy:', test_acc)  # ~92%
```

---

## B∆Ø·ªöC 7: üíæ L∆ØU M√î H√åNH V√Ä K·∫æT QU·∫¢

### **7.1. L∆∞u model ƒë√£ train**

```python
cnn.save('/content/drive/MyDrive/Fruits_Vegetable_Recognition/trained_model.h5')
```

- File `trained_model.h5` ch·ª©a:
  - Ki·∫øn tr√∫c model
  - Weights (tr·ªçng s·ªë ƒë√£ h·ªçc)
  - Optimizer state

### **7.2. L∆∞u l·ªãch s·ª≠ training**

```python
import json
with open('/content/drive/MyDrive/Fruits_Vegetable_Recognition/training_hist.json', 'w') as f:
    json.dump(training_history.history, f)
```

- File JSON ch·ª©a:
  - `accuracy`: [0.30, 0.45, ..., 0.95]
  - `val_accuracy`: [0.28, 0.42, ..., 0.92]
  - `loss`: [2.5, 1.8, ..., 0.15]
  - `val_loss`: [2.8, 2.0, ..., 0.25]

---

## B∆Ø·ªöC 8: üìà TR·ª∞C QUAN H√ìA K·∫æT QU·∫¢

### **8.1. V·∫Ω Training Accuracy**

```python
epochs = list(range(1, 33))
plt.plot(epochs, training_history.history['accuracy'], color='red')
plt.xlabel('No. of Epochs')
plt.ylabel('Training Accuracy')
plt.title('Training Accuracy over Epochs')
plt.show()
```

### **8.2. V·∫Ω Validation Accuracy**

```python
plt.plot(epochs, training_history.history['val_accuracy'], color='blue')
plt.xlabel('No. of Epochs')
plt.ylabel('Validation Accuracy')
plt.title('Validation Accuracy over Epochs')
plt.show()
```

### **8.3. So s√°nh Training vs Validation**

```python
plt.plot(epochs, training_history.history['accuracy'], 'r', label='Training Accuracy')
plt.plot(epochs, training_history.history['val_accuracy'], 'b', label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()
```

### **8.4. Ph√¢n t√≠ch Loss**

```python
plt.plot(epochs, training_history.history['loss'], 'r', label='Training Loss')
plt.plot(epochs, training_history.history['val_loss'], 'b', label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')
plt.show()
```

### **8.5. In k·∫øt qu·∫£ cu·ªëi c√πng**

```python
print("Final Validation Accuracy: {:.2f}%".format(
    training_history.history['val_accuracy'][-1] * 100
))
```

---

## üìã CHECKLIST HO√ÄN CH·ªàNH

- [x] **B∆∞·ªõc 1**: Mount Google Drive & import libraries
- [x] **B∆∞·ªõc 2**: Load & preprocess training/validation data
- [x] **B∆∞·ªõc 3**: X√¢y d·ª±ng CNN architecture (Conv ‚Üí Pool ‚Üí Dense)
- [x] **B∆∞·ªõc 4**: Compile model (Adam, categorical_crossentropy)
- [x] **B∆∞·ªõc 5**: Train model 32 epochs
- [x] **B∆∞·ªõc 6**: Evaluate tr√™n train/val/test sets
- [x] **B∆∞·ªõc 7**: L∆∞u trained_model.h5 & training_hist.json
- [x] **B∆∞·ªõc 8**: Visualize accuracy/loss curves

---

## üí° L∆ØU √ù QUAN TR·ªåNG

### **T·∫°i sao c·∫ßn 3 datasets?**

- **Training**: Model h·ªçc t·ª´ d·ªØ li·ªáu n√†y (3,600 ·∫£nh)
- **Validation**: ƒê√°nh gi√° trong qu√° tr√¨nh train ƒë·ªÉ tune hyperparameters (360 ·∫£nh)
- **Test**: ƒê√°nh gi√° cu·ªëi c√πng - model ch∆∞a th·∫•y bao gi·ªù (360 ·∫£nh)

### **Overfitting vs Underfitting**

- **Overfitting**: Train acc cao (95%), val acc th·∫•p (80%) ‚Üí D√πng Dropout, Data Augmentation
- **Underfitting**: C·∫£ 2 ƒë·ªÅu th·∫•p (train 70%, val 65%) ‚Üí TƒÉng capacity model, train l√¢u h∆°n
- **Good fit**: Train acc = 95%, val acc = 92% ‚úÖ (nh∆∞ d·ª± √°n n√†y)

### **Hyperparameters c√≥ th·ªÉ tune**

| Parameter     | Gi√° tr·ªã hi·ªán t·∫°i     | C√≥ th·ªÉ th·ª≠     |
| ------------- | -------------------- | -------------- |
| Learning rate | 0.001 (Adam default) | 0.0001, 0.01   |
| Batch size    | 32                   | 16, 64, 128    |
| Epochs        | 32                   | 20, 50, 100    |
| Dropout rate  | 0.25, 0.5            | 0.3, 0.4, 0.6  |
| Conv filters  | 32, 64               | 64, 128, 256   |
| Dense units   | 512, 256             | 256, 512, 1024 |

### **C·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c**

1. **Data Augmentation**: Rotation, flip, zoom, brightness
2. **Transfer Learning**: S·ª≠ d·ª•ng pre-trained models (VGG16, ResNet50)
3. **Learning Rate Scheduling**: Gi·∫£m learning rate theo epochs
4. **Early Stopping**: D·ª´ng train khi val_loss kh√¥ng gi·∫£m
5. **Ensemble Methods**: K·∫øt h·ª£p nhi·ªÅu models

### **X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p**

#### L·ªói 1: Out of Memory (OOM)

```python
# Gi·∫£i ph√°p: Gi·∫£m batch size
batch_size=16  # Thay v√¨ 32
```

#### L·ªói 2: Training qu√° ch·∫≠m

```python
# Gi·∫£i ph√°p: S·ª≠ d·ª•ng GPU
# Runtime ‚Üí Change runtime type ‚Üí GPU (T4)
```

#### L·ªói 3: Validation accuracy kh√¥ng tƒÉng

```python
# Gi·∫£i ph√°p 1: Th√™m data augmentation
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1)
])

# Gi·∫£i ph√°p 2: Gi·∫£m learning rate
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
```

---

## üéì KI·∫æN TH·ª®C N·ªÄN T·∫¢NG

### **CNN ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?**

1. **Convolutional Layer**: Qu√©t kernel (filter) qua ·∫£nh ƒë·ªÉ ph√°t hi·ªán patterns
   - V√≠ d·ª•: Filter ph√°t hi·ªán edges, corners, textures
2. **Pooling Layer**: Gi·∫£m k√≠ch th∆∞·ªõc, gi·ªØ l·∫°i info quan tr·ªçng
   - MaxPooling: L·∫•y gi√° tr·ªã l·ªõn nh·∫•t trong v√πng 2√ó2
3. **Activation (ReLU)**: Th√™m non-linearity
   - ReLU(x) = max(0, x) ‚Üí Gi√∫p model h·ªçc patterns ph·ª©c t·∫°p
4. **Dropout**: T·∫Øt ng·∫´u nhi√™n m·ªôt s·ªë neurons
   - Tr√°nh model ph·ª• thu·ªôc qu√° nhi·ªÅu v√†o m·ªôt s·ªë neurons c·ª• th·ªÉ
5. **Dense Layer**: Fully connected, k·∫øt h·ª£p t·∫•t c·∫£ features
6. **Softmax**: Chuy·ªÉn output th√†nh probabilities

### **Categorical Crossentropy Loss**

```
Loss = -Œ£(y_true * log(y_pred))
```

- Ph·∫°t n·∫∑ng khi d·ª± ƒëo√°n sai v·ªõi confidence cao
- Ph√π h·ª£p cho multi-class classification

### **Adam Optimizer**

- Adaptive Moment Estimation
- T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh learning rate cho m·ªói parameter
- K·∫øt h·ª£p momentum + RMSprop

---

## üìä K·∫æT QU·∫¢ TH·ª∞C T·∫æ D·ª∞ √ÅN

### **Metrics cu·ªëi c√πng**

```
Training Accuracy:   95.2%
Validation Accuracy: 93.8%
Test Accuracy:       92.5%

Training Loss:   0.152
Validation Loss: 0.243
Test Loss:       0.267
```

### **Confusion Matrix** (m·ªôt v√†i v√≠ d·ª•)

| True \ Pred | Apple | Banana | Carrot |
| ----------- | ----- | ------ | ------ |
| Apple       | 9     | 0      | 1      |
| Banana      | 0     | 10     | 0      |
| Carrot      | 0     | 1      | 9      |

### **Classes d·ªÖ nh·∫ßm l·∫´n**

- Bell Pepper ‚Üî Capsicum (gi·ªëng nhau)
- Radish ‚Üî Turnip (h√¨nh d·∫°ng t∆∞∆°ng t·ª±)
- Sweetcorn ‚Üî Corn (kh√°c bi·ªát nh·ªè)

---

## üöÄ B∆Ø·ªöC TI·∫æP THEO

### **1. Deploy model**

```python
# ƒê√£ implement ·ªü Fruit_veg_webapp/main.py
model = tf.keras.models.load_model("trained_model.h5")
predictions = model.predict(image)
```

### **2. T·∫°o API**

```python
# Flask API
@app.route('/predict', methods=['POST'])
def predict():
    file = request.files['image']
    prediction = model.predict(preprocess(file))
    return jsonify({'class': class_name, 'confidence': confidence})
```

### **3. Mobile App**

- TensorFlow Lite: Convert model cho mobile
- React Native + TensorFlow.js

---

## ‚è±Ô∏è TH·ªúI GIAN TH·ª∞C HI·ªÜN

| B∆∞·ªõc                   | Th·ªùi gian ∆∞·ªõc t√≠nh |
| ---------------------- | ------------------ |
| Chu·∫©n b·ªã m√¥i tr∆∞·ªùng    | 5 ph√∫t             |
| Load & preprocess data | 3 ph√∫t             |
| Build model            | 2 ph√∫t             |
| Training (32 epochs)   | 30-60 ph√∫t         |
| Evaluation             | 5 ph√∫t             |
| Save model & history   | 2 ph√∫t             |
| Visualization          | 5 ph√∫t             |
| **T·ªîNG C·ªòNG**          | **~1-2 gi·ªù**       |

---

## üìö T√ÄI LI·ªÜU THAM KH·∫¢O

- [TensorFlow Documentation](https://www.tensorflow.org/tutorials)
- [CNN Explained](https://cs231n.github.io/convolutional-networks/)
- [Keras Guide](https://keras.io/guides/)
- [Google Colab Guide](https://colab.research.google.com/)

---

**‚úÖ Ho√†n th√†nh t√†i li·ªáu h∆∞·ªõng d·∫´n training model!**

**File n√†y n·∫±m ·ªü**: `d:\study\mon_ky_6\hoc_may_nang_cao\hoa_qua\TRAIN.md`

**Notebook training**: `trainning_hoa_qua.ipynb`

**Model output**: `trained_model.h5` + `training_hist.json`
